# ì´ë¯¸ì§€ ìº¡ì…”ë‹ ê¸°ëŠ¥ êµ¬í˜„

<table>
   <tr>
      <td>
        <img width="160px" src="https://user-images.githubusercontent.com/58671945/78890548-d085b100-7aa0-11ea-9723-b146362f6dc5.jpg"><br>
         ì„í˜„ìˆ˜<br>
         <i>Project dev & Front Developer</i><br>
         <i>SSAFY 2ê¸° êµìœ¡ìƒ</i>
      </td>
      <td>
        <img width="160px" src="https://user-images.githubusercontent.com/58671945/78890552-d1b6de00-7aa0-11ea-85af-76bce9309754.jpg"><br>
         ë¬¸ì¤€í˜¸<br>
         <i>Project dev & Front Developer</i><br>
         <i>SSAFY 2ê¸° êµìœ¡ìƒ</i>
      </td>
      <td>
        <img width="160px" src="https://lab.ssafy.com/webmobile1-sub1/s02p11d138/raw/develop/KakaoTalk_20200109_090135135.jpg"><br>
         í™ì„±ìš±<br>
         <i>Project Lead & Developer</i><br>
         <i>SSAFY 2ê¸° êµìœ¡ìƒ</i>
      </td>
      <td>
        <img width="160px" src="https://user-images.githubusercontent.com/58671945/78890557-d380a180-7aa0-11ea-9d6d-2fef84900de9.jpg"><br>
         ì˜¤ì„¸ë´‰<br>
         <i>Project dev & Back Developer</i><br>
         <i>SSAFY 2ê¸° êµìœ¡ìƒ</i>
      </td>
      <td>
        <img width="160px" src="https://user-images.githubusercontent.com/58671945/78890559-d4b1ce80-7aa0-11ea-80a2-6231f6a8f1ed.jpg"><br>
         ë°•ì°¬í™˜<br>
         <i>Project dev & Back Developer</i><br>
         <i>SSAFY 2ê¸° êµìœ¡ìƒ</i>
      </td>
   </tr>
</table>

## ğŸ¤² OverView<br> 

## âœ¨ Prequuisited<br>





### develop machine Spec

>- Gitlab - SSAFY gitlab ì‚¬ìš©í•©ë‹ˆë‹¤. ë¬¸ì œ ë°œìƒì‹œ [gitLab docs](https://lab.ssafy.com/help)ë¥¼ í™œìš©í•©ë‹ˆë‹¤.
>- Vue.js - VS Code ì„¤ì¹˜ ë° [Vue.js ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://kr.vuejs.org/index.html) ë° [StackOverflow](https://stackoverflow.com/)ë¥¼ í†µí•´ ì‹œì‘í•©ë‹ˆë‹¤
>- Jira - [SSAFY jira](https://jira.ssafy.com/secure/Dashboard.jspa)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. jiraë¥¼ í†µí•´ issue ë° WorkFlow ë“± ì „ë°˜ì ì¸ ìŠ¤í”„ë¦°íŠ¸ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
>- MySQL
>- django





## ğŸ¥¨Commit/Branch Rules

### Commit

 #### Commit Message 7 Rules

> 1. ì œëª©ê³¼ ë³¸ë¬¸ì„ í•œ ì¤„ ë„ì›Œ ë¶„ë¦¬í•˜ê¸°
> 2. ì œëª©ì€ ì˜ë¬¸ ê¸°ì¤€ 50ì ì´ë‚´ë¡œ
> 3. ì œëª© ì²«ê¸€ìë¥¼ ëŒ€ë¬¸ìë¡œ
> 4. ì œëª© ëì— . ê¸ˆì§€
> 5. ì œëª©ì€ ëª…ë ¹ì¡°ë¡œ
> 6. ë³¸ë¬¸ì€ ì˜ë¬¸ ê¸°ì¤€ 72ìë§ˆë‹¤ ì¤„ ë°”ê¾¸ê¸°
> 7. ë³¸ë¬¸ì€ ì–´ë–»ê²Œë³´ë‹¤ ë¬´ì—‡ì„, ì™œì— ë§ì¶° ì‘ì„±í•˜ê¸°

 #### ë‹¨ì–´ ëª©ë¡

> ##### ê¸°ë³¸ì ìœ¼ë¡œ [íƒ€ì…] "ë¬´ì—‡ì„" + "ì™œ" í˜•ì‹ìœ¼ë¡œ ê´€ë¦¬
>
> 1. ìˆ˜ì • :: fix
>
> ```
> //ë¹„ì •ìƒì  ë™ì‘ì¼ ë•Œ, 
> //ë²„ê·¸ ì¡ì„ ë•Œ,
> [Fix] "ë¬´ì—‡ì„" + ("ì™œ")
> ```

> 2. ìˆ˜ì • :: update
>
> ```
> //ì •ìƒì ìœ¼ë¡œ ë™ì‘í•  ë•Œ, ìˆ˜ì •,ì¶”ê°€,ë³´ì™„í•  ë•Œ
> [Update] "ë¬´ì—‡ì„" + ("ì™œ")
> ```

> 3. ì¶”ê°€ :: add
>
> ```
> [Add] "ë¬´ì—‡ì„" + ("ì™œ")
> ```

> 4. ì‚­ì œ :: remove
>
> ```
> [Remove] "ë¬´ì—‡ì„" + ("ì™œ")
> ```

> 5. ì „ë©´ ìˆ˜ì • :: refactor
>
> ```
> [Refactor] "ë¬´ì—‡ì„" + ("ì™œ")
> ```

### Branch Naming (ë¸Œëœì¹˜ ëª…ëª… ê·œì¹™)

> ##### > Gitlabì—ëŠ” masterì™€ develop ë¸Œëœì¹˜, ê·¸ë¦¬ê³  master ë¸Œëœì¹˜ì˜ TAGë§Œ ê´€ë¦¬í•œë‹¤.

> #### ê°œë°œì PC
>
> ê°œë°œìëŠ” PCì— release, hotfix, feature, issue ë¸Œëœì¹˜ë¥¼ ìƒì„±í•˜ì—¬ ì‘ì—…ì„ ì§„í–‰í•œë‹¤.
> ì‘ì—…ì´ ì™„ë£Œëœ ë¸Œëœì¹˜ëŠ” ë³‘í•©í›„ ì‚­ì œ ê°€ëŠ¥í•˜ë©°, Gitlabì— ë°˜ì˜í•˜ì§€ ì•ŠëŠ”ë‹¤.

> #### release ë¸Œëœì¹˜
>
> - develop ë¸Œëœì¹˜ë¡œë¶€í„° ìƒì„±í•˜ëŠ” ë¸Œëœì¹˜ì´ë‹¤.
> - ëª…ëª… ê·œì¹™ : release/ë²„ì ¼ë„˜ë²„
>   ex) `release/2.0.0`
> - ë¸Œëœì¹˜ ìƒì„± í›„ì—ëŠ” ë²„ê·¸ í”½ìŠ¤ë§Œ ë°˜ì˜í•œë‹¤.
> - ìµœì¢… í™•ì • í›„ì—ëŠ” develop, master ë¸Œëœì¹˜ì— ë³‘í•©í•œë‹¤.

> #### feature ë¸Œëœì¹˜
>
> - develop ë¸Œëœì¹˜ë¡œë¶€í„° ìƒì„±í•˜ëŠ” ë¸Œëœì¹˜ì´ë‹¤.
> - ëª…ëª… ê·œì¹™ : ë…„ì›”ì¼_feature_ì§§ì€ì„¤ëª…
>   ex) `200207_feature_BoardTransition`
> - ì™„ë£Œ í›„ develop ë¸Œëœì¹˜ì— ë³‘í•©í•œë‹¤.



## ğŸ² íŒŒì¼/ë””ë ‰í„°ë¦¬ êµ¬ì¡°

- checkpoints/

  > í•™ìŠµëœ ëª¨ë¸ë“¤ì´ ì €ì¥ë˜ëŠ” í´ë”

- data/

  > ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì´ ìœ„ì¹˜í•œ í´ë”

- datasets/

  > ì‹¤ì œ ë°ì´í„°ê°€ ìœ„ì¹˜í•œ ê²½ë¡œ

- models/

  > ì´ë¯¸ì§€ ìº¡ì…”ë‹ ëª¨ë¸ì´ ìœ„ì¹˜í•œ ê²½ë¡œ

- utils/

  > ë°ì´í„° ì‹œê°í™”, í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì´ ìœ„ì¹˜í•œ ê²½ë¡œ

- config.py

  > ì„¤ì • ë³€ìˆ˜ë“¤ì´ ì €ì¥ëœ íŒŒì¼

- linear_regression.py

  > ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ í•™ìŠµ ë° ì‹œê°í™” ì˜ˆì‹œì½”ë“œê°€ ìˆëŠ” íŒŒì¼

- predict.py

  > í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•´ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ê²°ê³¼ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” íŒŒì¼

- train.py

  > ìº¡ì…”ë‹ ëª¨ë¸ í•™ìŠµ íŒŒì¼

## ğŸ¤¦ SetUp

### ì•„ë‚˜ì½˜ë‹¤ ì„¤ì¹˜

- [ì•„ë‚˜ì½˜ë‹¤ ë‹¤ìš´ë¡œë“œ ë§í¬](https//www.anaconda.com/distribution/) ì ‘ì†í›„ version 3.7 ë‹¤ìš´ë¡œë“œ

- ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒ í™˜ê²½ ìƒì„± ë° í™œì„±í™”

  ```bash
  conda create -n AI python = 3.7
  conda activate AI
  ```

- Tensorflow ë° í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

  ```bash
  conda install git matplotlib scikit-learn tqdm scipy numpy tesorflow-gpu=2.0.0
  ```

- ìƒ˜í”Œ ì‹¤í–‰ í™•ì¸

  ```bash
  <!--í”„ë¡œì íŠ¸ ìµœìƒë‹¨ ë””ë ‰í† ë¦¬ì—ì„œ í•  ê²ƒ.-->
  python linear_regression.py
  ```
  

## Req. 1 ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬

### Req. 1-1 ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ

preprocess.pyì˜ get_path_captioní•¨ìˆ˜ë¡œ 

train_dataset.csv, test_dataset.csvì—ì„œ ë°ì´í„°ì •ë³´ë¥¼ ë°›ì•„ì˜¨ ë’¤,

img_preprocess.pyì˜ img_preí•¨ìˆ˜ë¡œ ê° ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.

### Req. 1-2 ì´ë¯¸ì§€ ì •ê·œí™”

img_preprocess.pyì˜ img_preí•¨ìˆ˜ì—ì„œ ì´ë¯¸ì§€ê²½ë¡œì™€ ìº¡ì…˜ì„ ê°ê° ë¬¶ì–´ì„œ ì €ì¥í•œë‹¤.

train_test_splitìœ¼ë¡œ í•™ìŠµí•  ë°ì´í„°, í…ŒìŠ¤íŠ¸í•  ë°ì´í„°ë¥¼ ë‚˜ëˆˆë‹¤

```python
img_name_train, img_name_val, cap_train, cap_val = train_test_split(
    img_name_vector, cap_vector, test_size=0.2, random_state=0)
```



## Req. 2 í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬

### Req. 2-1 í…ìŠ¤íŠ¸ ë°ì´í„° í† í°í™”

my_token,pyì˜ tokenizationí•¨ìˆ˜ì—ì„œ ìº¡ì…˜ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ìˆ«ìë°ì´í„°ë¡œ í† í°í™”í•œë’¤ ë¦¬í„´í•œë‹¤.

### Req. 2-2 Tokenizer ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°

my_token,pyì˜ Save_Tokenizerì—ì„œ í† í° ì €ì¥ì„, Load_Tokenizerì—ì„œ í† í°ì„ ë¶ˆëŸ¬ì˜¨ë‹¤



## Req. 3 Dataset ìƒì„± í•¨ìˆ˜ êµ¬í˜„

### Req. 3-1 tf.data.Dataset ìƒì„±

pre_trained_model.pyì˜ Pre_trained_imgí•¨ìˆ˜ì—ì„œ ë°›ì•„ì˜¨ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í†µí•˜ì—¬ tf.data.Datasetì„ ìƒì„±í•œë‹¤.

```python
encode_train = sorted(set(img_name_vector))
    image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)
    image_dataset = image_dataset.map(
                            load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)
    image_model = tf.keras.applications.InceptionV3(include_top=False,
                                                    weights='imagenet')
```



### Req. 3-2 Image Data Augmentation

img_preprocess.pyì˜ img_preì—ì„œ ê° ì´ë¯¸ì§€ë¥¼ ë³€í˜•í•œë‹¤

```python
    datagen = image.ImageDataGenerator(
        rotation_range=5,
        width_shift_range=0.1,
        height_shift_range=0.1,
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.12,
        horizontal_flip=True,
        fill_mode='nearest')
```



## Req. 4 ì´ë¯¸ì§€ ëª¨ë¸ êµ¬í˜„

### Req. 4-1 Pre-trained ëª¨ë¸ë¡œ íŠ¹ì„± ì¶”ì¶œ

pre-trained ëª¨ë¸ : Inception, VGG, MobileNet, NASNet ë“±

InceptionV3ëª¨ë¸ì„ ì‚¬ìš©

Augumentation : ê°™ì€ ì‚¬ì§„ì„ ì“°ë”ë¼ë„ ê¸°ìš¸ì´ê±°ë‚˜ ìë¥´ê±°ë‚˜ ë’¤ì§‘ì–´ì„œ í•™ìŠµí•  ìë£Œë¥¼ ì¶”ê°€ë¡œ ìƒì„±

ImageDataGenerator ë¥¼ ì‚¬ìš©í•´ì„œ í•œ ì´ë¯¸ì§€ë‹¹ ì—¬ëŸ¬ê°€ì§€ì˜ ìë£Œë¥¼ ìƒì„±í•œë‹¤. 

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')

image = load_img('bird_resize.jpg', target_size=(220,200))
image = img_to_array(image)
image = image.reshape((1,) + image.shape)
i = 0
for batch in datagen.flow(image, batch_size=1,
                          save_to_dir='preview', save_prefix='bird', save_format='jpeg'):
    i += 1
    if i > 30:
        break  # ì´ë¯¸ì§€ 30ê°œ ìƒì„±
```

ê° ë³€ìˆ˜ ì°¸ê³ ìë£Œ : https://keras.io/preprocessing/image/

### Red. 4-2 Feature Encoder êµ¬í˜„

ì´ë¯¸ì§€ í¬ê¸°ë¥¼

220x200x3 - 220x200x64 - 110x100x128 - 55x50x256 - 27x25x512 - 13x12x512 ìˆœì„œë¡œ Encoding

glob : í´ë” ë‚´ì˜ íŠ¹ì • íŒŒì¼ëª…ë§Œ ëª¨ì•„ì¤Œ





## Req. 5 í…ìŠ¤íŠ¸ ëª¨ë¸ êµ¬í˜„

### Req. 5-1 ì„ë² ë”© ë ˆì´ì–´ êµ¬í˜„

í† í°í™”ëœ ë²¡í„°ë¥¼ ì§€ì •í•œ ê³µê°„ì— íˆ¬ì˜

```
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)

```



### Req. 5-2 RNN ëª¨ë¸ êµ¬í˜„

ì„ë² ì¸ ëœ ë²¡í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” RNN ëª¨ë¸ì„ êµ¬í˜„

```
        self.gru = tf.keras.layers.GRU(self.units,
                                       return_sequences=True,
                                       return_state=True,
                                       recurrent_initializer='glorot_uniform')
```



### Req. 5-3 ì—­ì„ë² ë”© ë ˆì´ì–´ êµ¬í˜„

ê²°ê³¼ê°’ì„ í† í°í™” ëœ ì •ë‹µ ë°ì´í„°ì™€ ë¹„êµ ê°€ëŠ¥í•˜ê²Œ ì°¨ì›ì„ ë³€í˜•

```
        self.fc1 = tf.keras.layers.Dense(self.units)
        self.fc2 = tf.keras.layers.Dense(vocab_size)
```



## Req. 6 train.py êµ¬í˜„

### Req. 6-1 ì†ì‹¤ í•¨ìˆ˜ êµ¬í˜„
ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µê°’ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì†ì‹¤ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„

```
        features = encoder(img_tensor)

        for i in range(1, target.shape[1]):
            predictions, hidden, _ = decoder(dec_input, features, hidden)

            loss += loss_function(target[:, i], predictions)

            dec_input = tf.expand_dims(target[:, i], 1)
```

### Req. 6-2 1-batch train step êµ¬í˜„
ë°°ì¹˜ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ ì†ì‹¤ì„ ê³„ì‚°í•˜ê³  ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” í•¨ìˆ˜ êµ¬í˜„

```
    with tf.GradientTape() as tape:
total_loss = (loss / int(target.shape[1]))

    trainable_variables = encoder.trainable_variables + decoder.trainable_variables

    gradients = tape.gradient(loss, trainable_variables)
```



### Req. 6-3 train.py ì™„ì„±
ì—¬ê¸°ê¹Œì§€ êµ¬í˜„ëœ ì „ì²˜ë¦¬, ëª¨ë¸, ìµœì í™”í•¨ìˆ˜ë° ì†ì‹¤í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ê³¼ì • êµ¬í˜„

```
BATCH_SIZE = 2048

EPOCHS = 30
num_steps = len(img_name_train) // BATCH_SIZE

for epoch in range(start_epoch, EPOCHS):
    start = time.time()
    total_loss = 0

    for (batch, (img_tensor, target)) in enumerate(dataset):
        batch_loss, t_loss = pre_trained_model.train_step(img_tensor, target, encoder, decoder, tokenizer, optimizer)
        total_loss += t_loss

        if batch % 100 == 0:
            print ('Epoch {} Batch {} Loss {:.4f}'.format(
                epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))
    # storing the epoch end loss value to plot later
    loss_plot.append(total_loss / num_steps)

    if epoch % 5 == 0:
        ckpt_manager.save()

    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,
                                         total_loss/num_steps))
    print ('Time taken for 1 epoch {} sec\n'.format(time.time() - start))


```





## Req. 7 predict.py êµ¬í˜„



### Req. 7-1 ìº¡ì…˜ ìƒì„± í•¨ìˆ˜ êµ¬í˜„
ìº¡ì…˜ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„

```
rid = np.random.randint(0, len(img_name_val))
image = img_name_val[rid]
real_caption = ' '.join([tokenizer.index_word[i] for i in cap_val[rid] if i not in [0]])
result, attention_plot = pre_trained_model.evaluate(image, max_length, attention_features_shape, encoder, decoder, pre_trained_model, image_features_extract_model, tokenizer)

print ('Real Caption:', real_caption)
print ('Prediction Caption:', ' '.join(result))
pre_trained_model.plot_attention(image, result, attention_plot)

```



### Req. 7-2 predict.py êµ¬í˜„

ëœë¤í•œ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì„œ ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì„ ë¹„êµí•˜ëŠ” ê³¼ì • êµ¬í˜„

```
def plot_attention(image, result, attention_plot):
    temp_image = np.array(Image.open(image))

    fig = plt.figure(figsize=(10, 10))

    len_result = len(result)
    for l in range(len_result):
        temp_att = np.resize(attention_plot[l], (8, 8))
        ax = fig.add_subplot(len_result//2, len_result//2, l+1)
        ax.set_title(result[l])
        img = ax.imshow(temp_image)
        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent())

    plt.tight_layout()
    plt.show()
```



## Req. 8 ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì €



### Req. 8-1 ì²´í¬í¬ì¸íŠ¸ ìƒì„± ë° ì €ì¥ í•¨ìˆ˜ êµ¬í˜„
CheckpointManagerë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì˜ ë³€ìˆ˜ë“¤ì„ ì €ì¥

```
checkpoint_path = "./checkpoints/train"
ckpt = tf.train.Checkpoint(encoder=encoder,
                           decoder=decoder,
                           optimizer = optimizer)
ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)

start_epoch = 0
```



### Req. 8-2 ì²´í¬í¬ì¸íŠ¸ ë¡œë” êµ¬í˜„
checkpoints/trainì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ë¡œë”ë¥¼ êµ¬í˜„

```
if ckpt_manager.latest_checkpoint:
    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])
    # restoring the latest checkpoint in checkpoint_path
    ckpt.restore(ckpt_manager.latest_checkpoint)

```




