# ğŸ¥ ì¸ê³µì§€ëŠ¥ í”„ë¡œì íŠ¸

<br>

## Core Team ğŸ˜œ

<table>
   <tr>
      <td>
        <img width="160px" src="https://lab.ssafy.com/webmobile1-sub1/s02p11d138/raw/develop/KakaoTalk_20200109_090135135.jpg"><br>
         [í™ì„±ìš±](https://github.com/Woogie924)<br>
         <i>Project lead & Developer</i><br>
         <i>SSAFY 2ê¸° êµìœ¡ìƒ</i>
      </td>
   </tr>
</table>

## ğŸ¤² OverView<br>

### Goal

> - ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹  ëŸ¬ë‹ì— ëŒ€í•œ ì´í•´
> - ì„ í˜• íšŒê·€ ë° ê²½ì‚¬ í•˜ê°•ë²•ì— ëŒ€í•œ ì´í•´
> - ì„ í˜• íšŒê·€ ëª¨ë¸ êµ¬í˜„
> - ì´ë¯¸ì§€ ìº¡ì…”ë‹ ë°ì´í„° ì „ì²˜ë¦¬
> - ë°ì´í„° ì‹œê°í™”

### ğŸ“Œì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í”„ë ˆì„ì›Œí¬

- **Numpy**
  - Scientific Computingì„ íŒŒì´ì¬ì—ì„œ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì§„ Python íŒ¨í‚¤ì§€
- **Matplotlib**
  - ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•´ ì‚¬ìš©ë˜ëŠ” íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Tensorflow**
  - êµ¬ê¸€ì—ì„œ ì œê³µí•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ **End-to-End**ì˜¤í”ˆì†ŒìŠ¤ í”Œë«í¼
  - **Tensorboard** ì‹œê°í™” íˆ´ì„ ì œê³µ-> í•™ìŠµ ê³¼ì • ë° ì—°ì‚° ê·¸ë˜í”„, ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ì‰¬ì›€
- **Keras**
  - Pythonìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, Tensorflow,CNTK,Teeanoì™€ ê°™ì€ Deep Learning ë¼ì´ë¸ŒëŸ¬ë¦¬ ìœ„ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” High-level Neural Network API
  - ëª¨ë“ˆì„±ê³¼ ì‰¬ìš´ í™•ì¥ì„±
- **json**
- **argsparse**

## ğŸ« ê¸°ëŠ¥/ê³¼ì œ ëª©ë¡

### ì§„ì²™ë¥  100%

<table>
<tr><th>Req</th><th>Category</th></tr>
<tr><td>1</td><td>ë‹¨ìˆœ ì„ í˜• íšŒê·€ ëª¨ë¸ êµ¬í˜„</td></tr>
<tr><td>2</td><td>ì´ë¯¸ì§€ ìº¡ì…”ë‹ Configuration</td></tr>
<tr><td>3</td><td>ì´ë¯¸ì§€ ìº¡ì…”ë‹ ë°ì´í„° ì „ì²˜ë¦¬</td></tr>
<tr><td>4</td><td>ë°ì´í„° ì‹œê°í™”</td></tr>
</table>
<br>

## ğŸ² íŒŒì¼/ë””ë ‰í„°ë¦¬ êµ¬ì¡°

- checkpoints/
  > í•™ìŠµëœ ëª¨ë¸ë“¤ì´ ì €ì¥ë˜ëŠ” í´ë”
- data/
  > ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì´ ìœ„ì¹˜í•œ í´ë”
- datasets/
  > ì‹¤ì œ ë°ì´í„°ê°€ ìœ„ì¹˜í•œ ê²½ë¡œ
- models/
  > ì´ë¯¸ì§€ ìº¡ì…”ë‹ ëª¨ë¸ì´ ìœ„ì¹˜í•œ ê²½ë¡œ
- utils/
  > ë°ì´í„° ì‹œê°í™”, í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì´ ìœ„ì¹˜í•œ ê²½ë¡œ
- config.py
  > ì„¤ì • ë³€ìˆ˜ë“¤ì´ ì €ì¥ëœ íŒŒì¼
- linear_regression.py
  > ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ í•™ìŠµ ë° ì‹œê°í™” ì˜ˆì‹œì½”ë“œê°€ ìˆëŠ” íŒŒì¼
- predict.py
  > í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•´ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ê²°ê³¼ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” íŒŒì¼
- train.py
  > ìº¡ì…”ë‹ ëª¨ë¸ í•™ìŠµ íŒŒì¼

## ğŸ¤¦ SetUp

### ì•„ë‚˜ì½˜ë‹¤ ì„¤ì¹˜

- [ì•„ë‚˜ì½˜ë‹¤ ë‹¤ìš´ë¡œë“œ ë§í¬](https//www.anaconda.com/distribution/) ì ‘ì†í›„ version 3.7 ë‹¤ìš´ë¡œë“œ

- ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒ í™˜ê²½ ìƒì„± ë° í™œì„±í™”

  ```bash
  conda create -n AI python = 3.7
  conda activate AI
  ```

- Tensorflow ë° í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

  ```bash
  conda install git matplotlib scikit-learn tqdm scipy numpy tesorflow-gpu=2.0.0
  ```

- ìƒ˜í”Œ ì‹¤í–‰ í™•ì¸
  ```bash
  <!--í”„ë¡œì íŠ¸ ìµœìƒë‹¨ ë””ë ‰í† ë¦¬ì—ì„œ í•  ê²ƒ.-->
  python linear_regression.py
  ```

### ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ

- ì´ë¯¸ì§€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ: [https://i02lab1.p.ssafy.io/images.zip (4.07GB)](https://i02lab1.p.ssafy.io/images.zip)
- ë‹¤ìš´ë¡œë“œ ë°›ì€ íŒŒì¼ì„ datasets í´ë”ì—ì„œ ì••ì¶• í•´ì œ

### VSCodeë¡œ ì•„ë‚˜ì½˜ë‹¤ ì‚¬ìš©í•˜ê¸°

- ì°¸ê³  ë§í¬ : [ì°¸ê³ ë§í¬](https://blog.naver.com/PostView.nhn?blogId=sbd38&logNo=221353609570&parentCategoryNo=&categoryNo=31&viewDate=&isShowPopularPosts=true&from=search)

## ğŸˆ Knowledge

### ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹

> ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì— ê°€ê¹Œìš´ ê¸°ëŠ¥ì„ ê°–ì¶˜ ì»´í“¨í„° ì‹œìŠ¤í…œ
> **ë¨¸ì‹ ëŸ¬ë‹ì€ ì´ëŸ¬í•œ ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ëŠ” êµ¬ì²´ì ì¸ ì ‘ê·¼ ë°©ì‹**

- ì»´í“¨í„°ê°€ ë°ì´í„°ë¥¼ í•™ìŠµí•¨ìœ¼ë¡œì¨, ê¸°ì¡´ ë°ì´í„°ì™€ ìœ ì‚¬í•˜ì§€ë§Œ ì²˜ìŒë³´ëŠ” ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê¸°ë²•
- ëª…ì‹œì  í”„ë¡œê·¸ë˜ë°ì´ë¼ê³ ë„ í•œë‹¤. > ì»´í“¨í„°ì—ê²Œ ì–´ë–»ê²Œ ë™ì‘í• ì§€, ì‚¬ëŒì´ ì½”ë“œë¥¼ í†µí•´ ëª…ì‹œì ìœ¼ë¡œ ì§€ì‹œí•¨.

#### ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì°¾ê¸°

1. ê´€ê³„ê°€ ì„ í˜• ê´€ê³„ì¸ì§€, ë¹„ì„ í˜• í˜•íƒœì¸ì§€?
2. ëª¨ë¸ ì„ íƒ(ì˜ˆë¥¼ ë“¤ì–´ 1ì°¨ ì„ í˜•ê´€ê³„ë¥¼ ì„ íƒí–ˆë‹¤ê³  í•˜ì)
3. ìµœì ì˜ ë³€ìˆ˜ë¥¼ ì°¾ì•„ì•¼í•œë‹¤.
4. ìµœì ì´ ì¡´ì¬í•˜ë ¤ë©´ ë‹¤ë¥¸ ë³€ìˆ˜ì™€ ë¹„êµí•  ìˆ˜ ìˆëŠ” ì²™ë„ê°€ í•„ìš”í•˜ë‹¤

   > ì´ë•Œ ë°”ë¡œ ì†ì‹¤ í•¨ìˆ˜(Cost Function)ê°€ í•„ìš”í•˜ë‹¤.

### ë”¥ ëŸ¬ë‹ì´ë€?

> ì‹¬ì¸µ ì‹ ê²½ë§(Deep Neural network)ì„ ì‚¬ìš©í•œ ë¨¸ì‹  ëŸ¬ë‹

#### Deep Neural Network

> ë” ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ íŠ¹ì„± ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ì„œ 2ê°œ ì´ìƒì˜ ì‹ ê²½ë§ì¸µì„ ìŒ“ì€ ëª¨ë¸

#### ì¸ê²½ ì‹ ê²½ë§

> ë¨¸ì‹  ëŸ¬ë‹ ë°©ë²• ì¤‘ ìƒë¬¼í•™ì  ì‹ ê²½ë§ì˜ ì‹œëƒ…ìŠ¤ ê²°í•¨ì„ ëª¨ë°©í•œ ëª¨ë¸

### ì„ í˜• íšŒê·€(Linear Regression)

- ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” ì§ì„ ì„ ì°¾ëŠ” ë¬¸ì œ

  - Y = WX + B í˜•íƒœ ( W = ê¸°ìš¸ê¸° , B = í¸ì°¨)

- [ê²½ì‚¬í•˜ê°•ë²•](https://www.youtube.com/watch?v=ve6gtpZV83E)

### ì†ì‹¤í•¨ìˆ˜

- ëª¨ë¸ì„ ì„ íƒí•œ í›„ì—ëŠ” ìµœì ì˜ ë³€ìˆ˜ë¥¼ ì°¾ì•„ì•¼í•˜ëŠ”ë°, ìµœì ì´ ì¡´ì¬í•˜ë ¤ë©´ ì„œë¡œ ë‹¤ë¥¸ ë³€ìˆ˜ì˜ ì¡°í•©ë“¤ì„ ë¹„êµí•  ìˆ˜ ìˆëŠ” ì²™ë„ê°€ í•„ìš”í•¨ ==> ì´ë•Œ ì‚¬ìš© ë˜ëŠ” ê²ƒì´ ì†ì‹¤í•¨ìˆ˜

- í•˜ë‚˜ë§Œ ìˆëŠ” ê²Œ ì•„ë‹ˆë¼ í”„ë¡œì íŠ¸ì˜ ëª©í‘œì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì •ì˜ë˜ê³  ë³€í˜•

- ëŒ€í‘œì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜

  - í‰ê·  ì œê³± í¸ì°¨ (i=1 ~~ i=N)
    $$
    MSE = 1/nâˆ‘(y_i-y_i^*)^2
    $$

- ìµœì í™” ë°©ë²• ==Â [ê²½ì‚¬í•˜ê°•ë²•](https://www.youtube.com/watch?v=ve6gtpZV83E)

## ğŸ’ êµ¬í˜„

### ğŸ”ë‹¨ìˆœ ì„ í˜• íšŒê·€ ëª¨ë¸ êµ¬í˜„

#### ë°ì´í„° ì½ê¸° ë° ì‹œê°í™”

##### ë°ì´í„° ì½ì–´ì˜¤ê¸°

- np.load : í•´ë‹¹ ê²½ë¡œì˜ npyíŒŒì¼ì„ ì½ì–´ì˜¤ê¸°

```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

train_data = np.load(".\\datasets\\linear_train.npy")
print(train_data)
```

##### ë°ì´í„° ë‹¤ë“¬ê¸°

- expend_dims
  - ì°¨ì›ì„ ëŠ˜ë¦¬ëŠ” í•¨ìˆ˜
  - xê°’ë“¤ì„ ê°ê° ë¦¬ìŠ¤íŠ¸ì— ë„£ê¸° ìœ„í•´ axisë¥¼ 1ë¡œ ì‚¬ìš©
  - 0ì´ë©´ `x_data = train_data[:,0]`ê³¼ ë™ì¼

```python
x_data = np.expand_dims(train_data[:,0], axis=1)
y_data = train_data[:,1]
```

##### ë°ì´í„° í‘œì‹œ

- plt.scatter
  > scatter(y,x,s,c)
  - `x`: xì¶• ê°’ì„ ë°°ì—´ë¡œ ì…ë ¥
  - `y`: yì¶• ê°’ì„ ë°°ì—´ë¡œ ì…ë ¥
  - `s`: ì ì˜ í¬ê¸°
  - `c`: ì ì˜ ìƒ‰ìƒ
- plt.legend
  > legend()
  - ë²”ì£¼ë¥¼ ìë™ìœ¼ë¡œ ì¡ì•„ì¤€ë‹¤.
  - ê´„í˜¸ì•ˆì— `predict data`ë¥¼ ì…ë ¥í•˜ë©´ ë¼ë²¨ì— `predict data`ê°€ ì…ë ¥
- plt.show
  - ê·¸ë˜í”„ ê·¸ë¦¬ê¸°

#### ì„ í˜• ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„±

linear_model.pyì— ìƒì„±ë˜ì–´ ìˆëŠ” LinearModelí´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°

```python
from models.linear_model import LinearModel

model = LinearModel(1)
```

##### call í˜¸ì¶œ í…ŒìŠ¤íŠ¸

```python
print(model.call(tf.fill([1, 1], 10)))
```

#### ìµœì í™” í•¨ìˆ˜ ë° ì†ì‹¤ í•¨ìˆ˜ ë°”ì¸ë”©

- `tf.keras.optimizers`
  - í•™ìŠµ ê³¼ì • ì„¤ì •
  - Adadelta, Adagrad, Adam , Adamax, Frtl, Nadam, Optimizer, RMSprop, SGD ë“±ì´ ìˆìŒ
  - ì¼ì°¨í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•˜ì—¬ SGDë¥¼ ì‚¬ìš©
  ```python
  tf.keras.optimizers.SGD(learning_rate, momentum, nesterov, name)
  ```
        - learning_rate : í•™ìŠµì†ë„
        - momentum : í•´ë‹¹ ë°©í–¥ìœ¼ë¡œ SGDë¥¼ ê°€ì†í™”í•˜ê³  ì§„ë™ì„ ì™„í™”(0~1)
        - nesterov : nesterov ìš´ë™ëŸ‰ ì ìš© ì—¬ë¶€
        - name : ì´ë¦„
        - loss : ìµœì í™” ê³¼ì •ì—ì„œ ìµœì†Œí™”ë  ì†ì‹¤í•¨ìˆ˜ ì„¤ì •
            - MSE : mean_squared_error
        - metrics
            - MeanSquaredError() : `y_true`ì™€ `y_pred`ì‚¬ì´ì˜ í‰ê·  ì œê³± ë¡œê·¸ ì˜¤ë¥˜ ê³„ì‚°
  - metrics : í›ˆë ¨ì„ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•´ ì‚¬ìš©

#### ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ êµ¬í˜„

```python
model.fit(x=x_data,
		  y=y_data,
		  epochs=10,
		  batch_size=32)
```

- `x` : ì…ë ¥ ë°ì´í„°
- `y` : ë¼ë²¨ ê°’
- `batch_size` : ëª‡ ê°œì˜ ìƒ˜í”Œë¡œ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•  ê²ƒì¸ì§€ ì§€ì •
  - ì–¼ë§ˆë‚˜ ì§„í–‰í•œ ë’¤ ë¹„êµí•˜ëŠ”ì§€ ì§€ì •. í´ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ê°±ì‹ ì´ ì ì–´ì§
- `epochs` : ê°™ì€ ìë£Œë¡œ ë°˜ë³µí•™ìŠµí•  íšŸìˆ˜

#### ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”

> predictë¡œ ê¸°ì¡´ê°’ë“¤ì„ ì„ ìœ¼ë¡œ ë‚˜íƒ€ë‚´ê³ , linear_test_xë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ë§Œë“¬

```python
test_x = np.load(".\\datasets\\linear_test_x.npy")


calculate_degree = model.predict(x=x_data,
    					   		 batch_size=2)

prediction = model.predict(x=test_x,
    					   batch_size=2)

plt.scatter(x_data,y_data,s=20,label="linear train")
plt.scatter(x_data,calculate_degree,s=5,c="b",label="prediction data")
plt.scatter(test_x,prediction,s=5,c="r",label="prediction data")
plt.legend(['savedata', 'learndata', 'predict'])
plt.show()
```

### ğŸ”ì´ë¯¸ì§€ ìº¡ì…”ë‹ Configuration

- config.py

```python
import argparse

# Req. 2-1	Config.py íŒŒì¼ ìƒì„±

# ì¸ìê°’ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
parser = argparse.ArgumentParser(description='ì´ë¯¸ì§€ ìº¡ì…”ë‹ ëª¨ë¸ Setting..')

# ì…ë ¥ë°›ì„ ì¸ìê°’ ë“±ë¡
# ìº¡ì…˜ ë°ì´í„°ê°€ ì €ì¥ëœ csv íŒŒì¼ì˜ ê²½ë¡œ
parser.add_argument('--caption_file_path', type=str,
                    default='.\\datasets\\captions.csv')
# ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ê²½ë¡œ
parser.add_argument('--image_file_path', type=str,
                    default='.\\datasets\\images\\')

# ìƒ˜í”Œë§ ì¶”ì¶œí•  ê°¯ìˆ˜
parser.add_argument('-s', '--do_sampling', type=int,
                    help="ìƒ˜í”Œë§ ì—¬ë¶€ ì§€ì •", default=0)

# ë°ì´í„° 1ê°œë‹¹ ë°˜ë³µí•™ìŠµí•  íšŸìˆ˜
parser.add_argument('--epochs', type=int, default=32)

# ëª‡ê°œì˜ ìƒ˜í”Œë‹¹ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•  ê²ƒì¸ì§€..
parser.add_argument('--batch_size', type=int, default=10)

# dataê°€ 1ì´ë©´ í•™ìŠµ ë°ì´í„°ì…‹ íŒ¨ìŠ¤, ì•„ë‹ˆë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ íŒ¨ìŠ¤
parser.add_argument("--data", type=int, default=1)

# ì…ë ¥ë°›ì€ ì¸ìê°’ argsì— ì €ì¥(type: namespace)
config = parser.parse_args()

# ì¸ìê°’ í…ŒìŠ¤íŠ¸
# print(config.caption_file_path)
# print(config.image_file_path)

```

- ì„¸íŒ… ê°’ ì €ì¥

```python
def save_config(args):
    data = dict()
    # ë°ì´í„° ìƒì„±
    # ìº¡ì…˜ íŒŒì¼ê²½ë¡œ
    data["caption_file_path"] = args.caption_file_path
    data["image_file_path"] = args.image_file_path
    data["do_sampling"] = args.do_sampling
    data["epochs"] = args.epochs
    data["batch_size"] = args.batch_size
    data["data"] = args.data

    with open('.\\settings.json', 'a', encoding='utf-8') as make_file:
        json.dump(data, make_file, indent="\t")
```

### ğŸ”ì´ë¯¸ì§€ ìº¡ì…”ë‹ ë°ì´í„° ì „ì²˜ë¦¬

- ì´ë¯¸ì§€ ê²½ë¡œ ë° ìº¡ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°

```python
def get_path_caption():
    img_paths = '.\\datasets\\images'
    csv_data = np.loadtxt('.\\datasets\\images\\results.csv',
                          delimiter='|', dtype="str", encoding="ISO-8859-1")

    # csv_data[i][0] : image_name
    # csv_data[i][1] : comment_number
    # csv_data[i][2] : comment

    # img_data[0] : ê²½ë¡œ
    # img_data[1]: comment 1
    # img_data[2]: comment 2
    # img_data[3]: comment 3
    # img_data[4]: comment 4
    # img_data[5]: comment 5
    img_data = ['', '', '', '', '', '']
    captions = []

    for i in range(1, len(csv_data), 5):
        img_data[0] = img_paths + '\\' + csv_data[i][0]
        img_data[1] = csv_data[i][2]
        img_data[2] = csv_data[i+1][2]
        img_data[3] = csv_data[i+2][2]
        img_data[4] = csv_data[i+3][2]
        img_data[5] = csv_data[i+4][2]
        captions.append(img_data[:])
    return img_paths, captions
```

- ì „ì²´ ë°ì´í„°ì…‹ì„ ë¶„ë¦¬í•´ ì €ì¥

```python
def dataset_split_save(captions):
    # caption : 158916 rows...
    train_dataset = []
    test_dataset = []

    # 1~5ë²ˆ commentì¤‘ ëœë¤ìœ¼ë¡œ í•™ìŠµ,í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    for i in range(len(captions)):
        num = random.randint(1, 5)
        if num < 2:
            train_dataset.append(captions[i])
        else:
            test_dataset.append(captions[i])

    # csvfile ì˜¤í”ˆ..
    # url, íŒŒì¼ ëª¨ë“œ, ì¸ì½”ë”© íƒ€ì… ì£¼ì˜
    # ì°¸ê³  ë§í¬ : https://m.blog.naver.com/PostView.nhn?blogId=real_77&logNo=221224637207&proxyReferer=https%3A%2F%2Fwww.google.com%2F
    csvfile = open(".\\datasets\\train_dataset.csv",
                   "w", newline="", encoding="utf-8")
    csvwriter = csv.writer(csvfile, quotechar="|", delimiter="|")

    for row in test_dataset:
        csvwriter.writerow(row)
    csvfile.close
    return ".\\datasets\\train_dataset.csv", ".\\datasets\\test_dataset_path"
```

- ì €ì¥ëœ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°

```python
def get_data_file(data, train_dataset_path, test_dataset_path):
    # data : parser.add_argument("--data", type=int, default=1)
    # train_dataset_path : ë¶„ë¦¬ëœ í•™ìŠµ ë°ì´í„°ì…‹ ê²½ë¡œ
    # test_dataset_path : ë¶„ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ

    # dataê°€ 1ì´ë©´ í•™ìŠµ ë°ì´í„°ì…‹ íŒ¨ìŠ¤, ì•„ë‹ˆë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ íŒ¨ìŠ¤
    if data == 1:
        caption = np.loadtxt(train_dataset_path,
                             delimiter='|', dtype="str", encoding="UTF8")
        img_paths = caption[:, 0]
    else:
        caption = np.loadtxt(test_dataset_path, delimiter='|',
                             dtype="str", encoding="UTF8")
        img_path = caption[:, 0]

    return img_paths, caption
```

- ë°ì´í„° ìƒ˜í”Œë§

```python
def sampling_data(img_paths, caption, sampling_count):
    if sampling_count > 10:
        return img_paths, caption
    cal_img_paths = []
    cal_csv_data = []

    for i in random.sample(list(range(len(caption))), sampling_count):
        cal_img_paths.append(caption[i][0])
        cal_csv_data.append(caption[i][1:6].tolist())
    return cal_img_paths, cal_csv_data
```

### ğŸ”ë°ì´í„° ì‹œê°í™”

- .png íŒŒì¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ `plt.imshow()` ì‚¬ìš©
  1. ê°€ìƒ í™˜ê²½ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
  ```bash
  conda install pillow
  ```
  2. í•´ë‹¹ pyíŒŒì¼ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
  ```python
  imgs = img.imread(img_paths[0])
  plt.title(caption[0][0])
  plt.imshow(imgs)
  plt.show()
  ```

## ğŸ˜‚í”„ë¡œì íŠ¸ ìˆ˜í–‰ ì‹œ ì–´ë ¤ì› ë˜ ì 

- python ë¬¸ë²•ì— ìµìˆ™í•˜ì§€ ì•Šì•„, ì ì‘í•˜ëŠ” ë° ì˜¤ë˜ ê±¸ë ¸ë‹¤.<br/>
  (í…ì„œí”Œë¡œ ë¬¸ì„œë‚˜, ë‹¤ë¥¸ ë ˆí¼ë¥¼ ì°¾ëŠ”ë° ë¬¸ë²•ë§ˆì € í—·ê°ˆë¦¬ë‹ˆ,,, ë©˜ë¶•ì˜ ì—°ì†,,)

- ê°œì¸ì ìœ¼ë¡œë„ ê³µë¶€í•´ì•¼í•  ì–‘ë“¤ì´ ë§ì€ ê²ƒê°™ë‹¤.
- ë”¥ëŸ¬ë‹ì´ ì“°ì´ëŠ” ìˆœì„œëŠ” í¬ê²ŒëŠ” ì•Œê² ì§€ë§Œ, ë¶€ë¶„ë§ˆë‹¤ ì„¸ë°€í•œ ë¡œì§ì„ íŒŒì•…í•˜ëŠ” ë° ì–´ë ¤ì› ë‹¤.
- ëª¨ë“  ëª¨ë¸ì˜ ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ì¦ëª…í•˜ëŠ” ê³¼ì •ì„ ë“£ê³  ë‚˜ë‹ˆ, í•œê²° ë‚˜ì•˜ë‹¤.
- ê°œì¸ì ì¸ ê³µë¶€ë¥¼ í•˜ëŠ” ë„ì¤‘ì—, **ì¤‘ê°„ì¤‘ê°„ ì§§ì€ ìŠ¤í¬ëŸ¼ì„ í†µí•´ íŒ€ì›ë“¤ê³¼ ê³µë¶€ ë‚´ìš©ì„ ê³µìœ í–ˆë‹¤. (ë§¤ìš° ì¤‘ìš”í•œë“¯..)**
- ì•„ì§ë„ ê°ˆê¸¸ì€ ë©€ì§€ë§Œ, í° ë¼ˆëŒ€ì— ì‚´ì„ ë¶™ì´ëŠ” ë°©ë²•ìœ¼ë¡œ ì¡°ê¸ˆì”© ê³µë¶€í•˜ì!!

## ğŸ“„ì°¸ê³ 

- [ì¸ê³µì§€ëŠ¥](https://brunch.co.kr/@gdhan/1)
- [ë¨¸ì‹ ëŸ¬ë‹](https://swalloow.github.io/pyml-introl)

- [ë¨¸ì‹ ëŸ¬ë‹](https://tykimos.github.io/2019/01/06/2018_ML_projects/)

- [ë”¥ëŸ¬ë‹](https://brunch.co.kr/2itschloel/23)

- [ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ - ì‹ ê²½ë§ì˜ êµ¬ì¡°](https://www.youtube.com/watch?v=aircAruvnKk)

- [ê²½ì‚¬í•˜ê°•ë²•](https://www.youtube.com/watch?v=IHZwWFHWa-w)

- [ì—­ì „íŒŒì˜ ê°œë…](https://www.youtube.com/watch?v=Ilg3gGewQ5U)

- [ì†ì‹¤í•¨ìˆ˜ - ëŒ€í‘œì ì¸ ì¢…ë¥˜](https://eehoeskrap.tistory.com/145)

- [ì†ì‹¤í•¨ìˆ˜ - í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ í•¨ìˆ˜](https://www.youtube.com/watch?v=uMYhthKw1PU)

- [íŒŒì´ì¬ ë¬¸ë²•](https://wikidocs.net/22)
- [json íŒŒì¼ ì €ì¥](http://blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221540272941)
- [argparse ëª¨ë“ˆ ë¬¸ì„œ](https://docs.python.org/ko/3.7/library/argparse.html)
- [csv íŒŒì¼ ì €ì¥ ê´€ë ¨(pandas)](https://hogni.tistory.com/10)
- [íŒŒì´ì¬ csvê°ì²´](https://m.blog.naver.com/PostView.nhn?blogId=real_77&logNo=221224637207&proxyReferer=https%3A%2F%2Fwww.google.com%2F)
